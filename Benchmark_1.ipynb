{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Benchmark.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1EtJZM1bMpemD8w_t6uLBgtb9YNf1-Oyj",
      "authorship_tag": "ABX9TyMsXB3xg/0rFibGuwcVzM6a",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vieduy/CS114.K21/blob/master/Benchmark_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FckG38bFQ5jg",
        "colab_type": "code",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "outputId": "6ead02bc-50ac-4e2d-cf1a-98a64c50eb3c"
      },
      "source": [
        "# Run this cell and select the kaggle.json file downloaded\n",
        "# from the Kaggle account settings page.\n",
        "from google.colab import files\n",
        "files.upload()"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-3a99b646-b87d-41ff-9e59-fe51039c0329\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-3a99b646-b87d-41ff-9e59-fe51039c0329\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving kaggle.json to kaggle.json\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'kaggle.json': b'{\"username\":\"duyhoangvien\",\"key\":\"0952d645a4b4335830e2e94ecdd947d0\"}'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DYfDgcSFRNg7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "fec8d3ab-f4fe-45ef-b27c-e3367072ca54"
      },
      "source": [
        "# Let's make sure the kaggle.json file is present.\n",
        "!ls -lha kaggle.json"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-rw-r--r-- 1 root root 68 Jun 24 15:04 kaggle.json\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ULa0JwaVRR8U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Next, install the Kaggle API client.\n",
        "!pip install -q kaggle"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qOLUIZotRVVw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# The Kaggle API client expects this file to be in ~/.kaggle,\n",
        "# so move it there.\n",
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "\n",
        "# This permissions change avoids a warning on Kaggle tool startup.\n",
        "!chmod 600 ~/.kaggle/kaggle.json"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F38zAH7qRZlF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# List available datasets.\n",
        "!kaggle datasets list"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AaYBTaIfRcl-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "f431ee8c-0e43-4a70-b183-76a98f1f5b68"
      },
      "source": [
        "!kaggle datasets download -d meowmeowmeowmeowmeow/gtsrb-german-traffic-sign --force"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading gtsrb-german-traffic-sign.zip to /content\n",
            " 99% 603M/612M [00:13<00:00, 44.6MB/s]\n",
            "100% 612M/612M [00:13<00:00, 46.8MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ij9mnTzgRjfn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!unzip gtsrb-german-traffic-sign.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s4p4Wh9y8Xrp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "088489d6-03fc-46e4-a1d8-2cdc093f35bc"
      },
      "source": [
        "cd drive/My\\ Drive"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mYF9MpErOnOK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib\n",
        "\n",
        "# import the necessary packages\n",
        "from scripts.preprocessing.imagetoarraypreprocessor import ImageToArrayPreprocessor\n",
        "from scripts.preprocessing.simplepreprocessor import SimplePreprocessor\n",
        "from scripts.preprocessing.patchpreprocessor import PatchPreprocessor\n",
        "from scripts.preprocessing.meanpreprocessor import MeanPreprocessor\n",
        "from scripts.callbacks.trainingmonitor import TrainingMonitor\n",
        "from scripts.io.hdf5datasetgenerator import HDF5DatasetGenerator\n",
        "from scripts.preprocessing.aspectawarepreprocessor import AspectAwarePreprocessor\n",
        "from scripts.cnn.alexnet import AlexNet\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from scripts.io.simpledatasetloader import SimpleDatasetLoader\n",
        "import json\n",
        "import os\n",
        "from imutils import paths\n",
        "import random\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gMMKREnyA65Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "aap = AspectAwarePreprocessor(64, 64)\n",
        "iap = ImageToArrayPreprocessor()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5-i7KlwGBFAa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "7c74e2db-3141-46d1-a305-f4df5d13f44b"
      },
      "source": [
        "imagePaths = list(paths.list_images('../../Train'))\n",
        "random.shuffle(imagePaths)\n",
        "trainPaths = imagePaths[:31368]\n",
        "testPaths = imagePaths[31368:]\n",
        "length_train = len(trainPaths)\n",
        "length_test = len(testPaths)\n",
        "sdl = SimpleDatasetLoader(preprocessors=[])\n",
        "(trainX, trainY) = sdl.load(trainPaths, verbose=500, length=length_train, name='../../train.hdf5')\n",
        "(testX, testY) = sdl.load(testPaths, verbose=500, length=length_test, name='../../val.hdf5')"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[INFO] processed 500/31368\n",
            "[INFO] processed 1000/31368\n",
            "[INFO] processed 1500/31368\n",
            "[INFO] processed 2000/31368\n",
            "[INFO] processed 2500/31368\n",
            "[INFO] processed 3000/31368\n",
            "[INFO] processed 3500/31368\n",
            "[INFO] processed 4000/31368\n",
            "[INFO] processed 4500/31368\n",
            "[INFO] processed 5000/31368\n",
            "[INFO] processed 5500/31368\n",
            "[INFO] processed 6000/31368\n",
            "[INFO] processed 6500/31368\n",
            "[INFO] processed 7000/31368\n",
            "[INFO] processed 7500/31368\n",
            "[INFO] processed 8000/31368\n",
            "[INFO] processed 8500/31368\n",
            "[INFO] processed 9000/31368\n",
            "[INFO] processed 9500/31368\n",
            "[INFO] processed 10000/31368\n",
            "[INFO] processed 10500/31368\n",
            "[INFO] processed 11000/31368\n",
            "[INFO] processed 11500/31368\n",
            "[INFO] processed 12000/31368\n",
            "[INFO] processed 12500/31368\n",
            "[INFO] processed 13000/31368\n",
            "[INFO] processed 13500/31368\n",
            "[INFO] processed 14000/31368\n",
            "[INFO] processed 14500/31368\n",
            "[INFO] processed 15000/31368\n",
            "[INFO] processed 15500/31368\n",
            "[INFO] processed 16000/31368\n",
            "[INFO] processed 16500/31368\n",
            "[INFO] processed 17000/31368\n",
            "[INFO] processed 17500/31368\n",
            "[INFO] processed 18000/31368\n",
            "[INFO] processed 18500/31368\n",
            "[INFO] processed 19000/31368\n",
            "[INFO] processed 19500/31368\n",
            "[INFO] processed 20000/31368\n",
            "[INFO] processed 20500/31368\n",
            "[INFO] processed 21000/31368\n",
            "[INFO] processed 21500/31368\n",
            "[INFO] processed 22000/31368\n",
            "[INFO] processed 22500/31368\n",
            "[INFO] processed 23000/31368\n",
            "[INFO] processed 23500/31368\n",
            "[INFO] processed 24000/31368\n",
            "[INFO] processed 24500/31368\n",
            "[INFO] processed 25000/31368\n",
            "[INFO] processed 25500/31368\n",
            "[INFO] processed 26000/31368\n",
            "[INFO] processed 26500/31368\n",
            "[INFO] processed 27000/31368\n",
            "[INFO] processed 27500/31368\n",
            "[INFO] processed 28000/31368\n",
            "[INFO] processed 28500/31368\n",
            "[INFO] processed 29000/31368\n",
            "[INFO] processed 29500/31368\n",
            "[INFO] processed 30000/31368\n",
            "[INFO] processed 30500/31368\n",
            "[INFO] processed 31000/31368\n",
            "[INFO] processed 500/7841\n",
            "[INFO] processed 1000/7841\n",
            "[INFO] processed 1500/7841\n",
            "[INFO] processed 2000/7841\n",
            "[INFO] processed 2500/7841\n",
            "[INFO] processed 3000/7841\n",
            "[INFO] processed 3500/7841\n",
            "[INFO] processed 4000/7841\n",
            "[INFO] processed 4500/7841\n",
            "[INFO] processed 5000/7841\n",
            "[INFO] processed 5500/7841\n",
            "[INFO] processed 6000/7841\n",
            "[INFO] processed 6500/7841\n",
            "[INFO] processed 7000/7841\n",
            "[INFO] processed 7500/7841\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Bhf18tqmWho",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.preprocessing import LabelBinarizer\n",
        "\n",
        "# convert the labels from integers to vectors\n",
        "trainX = trainX.astype(\"float\") / 255.0\n",
        "testX = testX.astype(\"float\") / 255.0\n",
        "\n",
        "trainY = LabelBinarizer().fit_transform(trainY)\n",
        "testY = LabelBinarizer().fit_transform(testY)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pjxsCrUrazIw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.preprocessing import LabelBinarizer\n",
        "import h5py\n",
        "\n",
        "db = h5py.File('../../train.hdf5', 'r')\n",
        "trainX = np.array(db[\"images\"])\n",
        "trainY = np.array(db[\"labels\"])"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YM7jReXJbrnb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "db_val = h5py.File('../../val.hdf5', 'r')\n",
        "testX = np.array(db[\"images\"])\n",
        "testY = np.array(db[\"labels\"])"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vT0bfcIvgPMm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def step_decay(epoch):\n",
        "  # initialize the base initial learning rate, drop factor, and\n",
        "  # epochs to drop every\n",
        "  initAlpha = 5e-4\n",
        "  factor = 0.5\n",
        "  dropEvery = 5\n",
        "\n",
        "  # compute learning rate for the current epoch\n",
        "  alpha = initAlpha * (factor ** np.floor((1 + epoch) / dropEvery))\n",
        "  # return the learning rate\n",
        "  return float(alpha)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qyKKQRWKI3_6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ab2b17d6-bea7-4d42-b653-be213a4a8423"
      },
      "source": [
        "# initialize the optimizer and model\n",
        "from scripts.cnn.alexnet import AlexNet\n",
        "from tensorflow.keras.callbacks import LearningRateScheduler\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "print(\"[INFO] compiling model...\")\n",
        "opt = Adam(lr=5e-4, decay=5e-4 / (30 * 0.5))\n",
        "model = AlexNet.build(width=64, height=64, depth=3,\n",
        "  classes=43, reg=0.0002)\n",
        "model.compile(loss=\"categorical_crossentropy\", optimizer=opt,\n",
        "  metrics=[\"accuracy\"])\n",
        "\n",
        "aug = ImageDataGenerator(\n",
        "\trotation_range=10,\n",
        "\tzoom_range=0.15,\n",
        "\twidth_shift_range=0.1,\n",
        "\theight_shift_range=0.1,\n",
        "\tshear_range=0.15,\n",
        "\thorizontal_flip=False,\n",
        "\tvertical_flip=False,\n",
        "\tfill_mode=\"nearest\")"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[INFO] compiling model...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f3SLsqheZHfI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "\n",
        "fname = os.path.sep.join(['output', \"weights-{epoch:03d}-{val_loss:.4f}.hdf5\"])\n",
        "checkpoint = ModelCheckpoint(fname, monitor=\"val_loss\", mode=\"min\", save_best_only=True, verbose=1)\n",
        "figPath = os.path.sep.join(['output', \"{}.png\".format(os.getpid())])\n",
        "jsonPath = os.path.sep.join(['output', \"{}.json\".format(os.getpid())])\n",
        "callbacks = [TrainingMonitor(figPath, jsonPath=jsonPath), checkpoint]"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IBjisRjVYJHU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "495ea540-a96a-4928-d758-2037e5761bd8"
      },
      "source": [
        "print(\"[INFO] training network...\")\n",
        "H = model.fit(\n",
        "\taug.flow(trainX, trainY, batch_size=128),\n",
        "\tvalidation_data=(testX, testY),\n",
        "\tsteps_per_epoch=trainX.shape[0] // 128,\n",
        "\tepochs=45, verbose=1, callbacks=callbacks)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[INFO] training network...\n",
            "Epoch 1/45\n",
            "245/245 [==============================] - ETA: 0s - loss: 4.3821 - accuracy: 0.2712\n",
            "Epoch 00001: val_loss improved from inf to 6.60048, saving model to output/weights-001-6.6005.hdf5\n",
            "245/245 [==============================] - 54s 220ms/step - loss: 4.3821 - accuracy: 0.2712 - val_loss: 6.6005 - val_accuracy: 0.0466\n",
            "Epoch 2/45\n",
            "245/245 [==============================] - ETA: 0s - loss: 2.3659 - accuracy: 0.6245\n",
            "Epoch 00002: val_loss improved from 6.60048 to 5.11881, saving model to output/weights-002-5.1188.hdf5\n",
            "245/245 [==============================] - 54s 221ms/step - loss: 2.3659 - accuracy: 0.6245 - val_loss: 5.1188 - val_accuracy: 0.1013\n",
            "Epoch 3/45\n",
            "245/245 [==============================] - ETA: 0s - loss: 1.7547 - accuracy: 0.8053\n",
            "Epoch 00003: val_loss improved from 5.11881 to 2.09078, saving model to output/weights-003-2.0908.hdf5\n",
            "245/245 [==============================] - 53s 215ms/step - loss: 1.7547 - accuracy: 0.8053 - val_loss: 2.0908 - val_accuracy: 0.6794\n",
            "Epoch 4/45\n",
            "245/245 [==============================] - ETA: 0s - loss: 1.4706 - accuracy: 0.8789\n",
            "Epoch 00004: val_loss improved from 2.09078 to 1.91985, saving model to output/weights-004-1.9199.hdf5\n",
            "245/245 [==============================] - 54s 219ms/step - loss: 1.4706 - accuracy: 0.8789 - val_loss: 1.9199 - val_accuracy: 0.7711\n",
            "Epoch 5/45\n",
            "245/245 [==============================] - ETA: 0s - loss: 1.3599 - accuracy: 0.8971\n",
            "Epoch 00005: val_loss did not improve from 1.91985\n",
            "245/245 [==============================] - 52s 214ms/step - loss: 1.3599 - accuracy: 0.8971 - val_loss: 3.1267 - val_accuracy: 0.5988\n",
            "Epoch 6/45\n",
            "245/245 [==============================] - ETA: 0s - loss: 1.1718 - accuracy: 0.9319\n",
            "Epoch 00006: val_loss improved from 1.91985 to 1.02533, saving model to output/weights-006-1.0253.hdf5\n",
            "245/245 [==============================] - 53s 215ms/step - loss: 1.1718 - accuracy: 0.9319 - val_loss: 1.0253 - val_accuracy: 0.9611\n",
            "Epoch 7/45\n",
            "245/245 [==============================] - ETA: 0s - loss: 1.0580 - accuracy: 0.9420\n",
            "Epoch 00007: val_loss did not improve from 1.02533\n",
            "245/245 [==============================] - 52s 213ms/step - loss: 1.0580 - accuracy: 0.9420 - val_loss: 1.1034 - val_accuracy: 0.9228\n",
            "Epoch 8/45\n",
            "245/245 [==============================] - ETA: 0s - loss: 0.9634 - accuracy: 0.9463\n",
            "Epoch 00008: val_loss did not improve from 1.02533\n",
            "245/245 [==============================] - 51s 210ms/step - loss: 0.9634 - accuracy: 0.9463 - val_loss: 1.0771 - val_accuracy: 0.9188\n",
            "Epoch 9/45\n",
            "245/245 [==============================] - ETA: 0s - loss: 0.8736 - accuracy: 0.9509\n",
            "Epoch 00009: val_loss improved from 1.02533 to 0.92005, saving model to output/weights-009-0.9201.hdf5\n",
            "245/245 [==============================] - 53s 217ms/step - loss: 0.8736 - accuracy: 0.9509 - val_loss: 0.9201 - val_accuracy: 0.9344\n",
            "Epoch 10/45\n",
            "245/245 [==============================] - ETA: 0s - loss: 0.8574 - accuracy: 0.9456\n",
            "Epoch 00010: val_loss did not improve from 0.92005\n",
            "245/245 [==============================] - 53s 216ms/step - loss: 0.8574 - accuracy: 0.9456 - val_loss: 1.0461 - val_accuracy: 0.8806\n",
            "Epoch 11/45\n",
            "245/245 [==============================] - ETA: 0s - loss: 0.8712 - accuracy: 0.9376\n",
            "Epoch 00011: val_loss did not improve from 0.92005\n",
            "245/245 [==============================] - 52s 212ms/step - loss: 0.8712 - accuracy: 0.9376 - val_loss: 1.0371 - val_accuracy: 0.8977\n",
            "Epoch 12/45\n",
            "245/245 [==============================] - ETA: 0s - loss: 0.8194 - accuracy: 0.9513\n",
            "Epoch 00012: val_loss improved from 0.92005 to 0.72382, saving model to output/weights-012-0.7238.hdf5\n",
            "245/245 [==============================] - 52s 214ms/step - loss: 0.8194 - accuracy: 0.9513 - val_loss: 0.7238 - val_accuracy: 0.9747\n",
            "Epoch 13/45\n",
            "245/245 [==============================] - ETA: 0s - loss: 0.7473 - accuracy: 0.9585\n",
            "Epoch 00013: val_loss did not improve from 0.72382\n",
            "245/245 [==============================] - 53s 216ms/step - loss: 0.7473 - accuracy: 0.9585 - val_loss: 0.9473 - val_accuracy: 0.8875\n",
            "Epoch 14/45\n",
            "245/245 [==============================] - ETA: 0s - loss: 0.8355 - accuracy: 0.9433\n",
            "Epoch 00014: val_loss did not improve from 0.72382\n",
            "245/245 [==============================] - 52s 213ms/step - loss: 0.8355 - accuracy: 0.9433 - val_loss: 0.7711 - val_accuracy: 0.9579\n",
            "Epoch 15/45\n",
            "245/245 [==============================] - ETA: 0s - loss: 0.7474 - accuracy: 0.9586\n",
            "Epoch 00015: val_loss did not improve from 0.72382\n",
            "245/245 [==============================] - 52s 214ms/step - loss: 0.7474 - accuracy: 0.9586 - val_loss: 0.9195 - val_accuracy: 0.9088\n",
            "Epoch 16/45\n",
            "245/245 [==============================] - ETA: 0s - loss: 0.7248 - accuracy: 0.9571\n",
            "Epoch 00016: val_loss did not improve from 0.72382\n",
            "245/245 [==============================] - 52s 214ms/step - loss: 0.7248 - accuracy: 0.9571 - val_loss: 0.8848 - val_accuracy: 0.9307\n",
            "Epoch 17/45\n",
            "245/245 [==============================] - ETA: 0s - loss: 0.7171 - accuracy: 0.9629\n",
            "Epoch 00017: val_loss improved from 0.72382 to 0.61179, saving model to output/weights-017-0.6118.hdf5\n",
            "245/245 [==============================] - 53s 218ms/step - loss: 0.7171 - accuracy: 0.9629 - val_loss: 0.6118 - val_accuracy: 0.9829\n",
            "Epoch 18/45\n",
            "245/245 [==============================] - ETA: 0s - loss: 0.7213 - accuracy: 0.9569\n",
            "Epoch 00018: val_loss did not improve from 0.61179\n",
            "245/245 [==============================] - 53s 216ms/step - loss: 0.7213 - accuracy: 0.9569 - val_loss: 1.3259 - val_accuracy: 0.8024\n",
            "Epoch 19/45\n",
            "245/245 [==============================] - ETA: 0s - loss: 0.8129 - accuracy: 0.9518\n",
            "Epoch 00019: val_loss did not improve from 0.61179\n",
            "245/245 [==============================] - 52s 213ms/step - loss: 0.8129 - accuracy: 0.9518 - val_loss: 0.6560 - val_accuracy: 0.9867\n",
            "Epoch 20/45\n",
            "245/245 [==============================] - ETA: 0s - loss: 0.6612 - accuracy: 0.9749\n",
            "Epoch 00020: val_loss improved from 0.61179 to 0.56826, saving model to output/weights-020-0.5683.hdf5\n",
            "245/245 [==============================] - 53s 215ms/step - loss: 0.6612 - accuracy: 0.9749 - val_loss: 0.5683 - val_accuracy: 0.9899\n",
            "Epoch 21/45\n",
            "245/245 [==============================] - ETA: 0s - loss: 0.6532 - accuracy: 0.9665\n",
            "Epoch 00021: val_loss did not improve from 0.56826\n",
            "245/245 [==============================] - 53s 216ms/step - loss: 0.6532 - accuracy: 0.9665 - val_loss: 1.5077 - val_accuracy: 0.7778\n",
            "Epoch 22/45\n",
            "245/245 [==============================] - ETA: 0s - loss: 0.6322 - accuracy: 0.9711\n",
            "Epoch 00022: val_loss did not improve from 0.56826\n",
            "245/245 [==============================] - 52s 214ms/step - loss: 0.6322 - accuracy: 0.9711 - val_loss: 0.5810 - val_accuracy: 0.9768\n",
            "Epoch 23/45\n",
            "245/245 [==============================] - ETA: 0s - loss: 0.5708 - accuracy: 0.9749\n",
            "Epoch 00023: val_loss did not improve from 0.56826\n",
            "245/245 [==============================] - 52s 213ms/step - loss: 0.5708 - accuracy: 0.9749 - val_loss: 0.6224 - val_accuracy: 0.9582\n",
            "Epoch 24/45\n",
            "245/245 [==============================] - ETA: 0s - loss: 0.5742 - accuracy: 0.9711\n",
            "Epoch 00024: val_loss did not improve from 0.56826\n",
            "245/245 [==============================] - 52s 212ms/step - loss: 0.5742 - accuracy: 0.9711 - val_loss: 0.6620 - val_accuracy: 0.9589\n",
            "Epoch 25/45\n",
            "245/245 [==============================] - ETA: 0s - loss: 0.6301 - accuracy: 0.9701\n",
            "Epoch 00025: val_loss improved from 0.56826 to 0.53272, saving model to output/weights-025-0.5327.hdf5\n",
            "245/245 [==============================] - 53s 216ms/step - loss: 0.6301 - accuracy: 0.9701 - val_loss: 0.5327 - val_accuracy: 0.9899\n",
            "Epoch 26/45\n",
            "245/245 [==============================] - ETA: 0s - loss: 0.6313 - accuracy: 0.9643\n",
            "Epoch 00026: val_loss did not improve from 0.53272\n",
            "245/245 [==============================] - 53s 217ms/step - loss: 0.6313 - accuracy: 0.9643 - val_loss: 0.7475 - val_accuracy: 0.9574\n",
            "Epoch 27/45\n",
            "245/245 [==============================] - ETA: 0s - loss: 0.6609 - accuracy: 0.9703\n",
            "Epoch 00027: val_loss did not improve from 0.53272\n",
            "245/245 [==============================] - 52s 211ms/step - loss: 0.6609 - accuracy: 0.9703 - val_loss: 0.5684 - val_accuracy: 0.9897\n",
            "Epoch 28/45\n",
            "245/245 [==============================] - ETA: 0s - loss: 0.5978 - accuracy: 0.9761\n",
            "Epoch 00028: val_loss improved from 0.53272 to 0.51925, saving model to output/weights-028-0.5193.hdf5\n",
            "245/245 [==============================] - 53s 216ms/step - loss: 0.5978 - accuracy: 0.9761 - val_loss: 0.5193 - val_accuracy: 0.9892\n",
            "Epoch 29/45\n",
            "245/245 [==============================] - ETA: 0s - loss: 0.5427 - accuracy: 0.9763\n",
            "Epoch 00029: val_loss did not improve from 0.51925\n",
            "245/245 [==============================] - 53s 216ms/step - loss: 0.5427 - accuracy: 0.9763 - val_loss: 1.1121 - val_accuracy: 0.8716\n",
            "Epoch 30/45\n",
            "245/245 [==============================] - ETA: 0s - loss: 0.5911 - accuracy: 0.9743\n",
            "Epoch 00030: val_loss did not improve from 0.51925\n",
            "245/245 [==============================] - 52s 211ms/step - loss: 0.5911 - accuracy: 0.9743 - val_loss: 0.5918 - val_accuracy: 0.9824\n",
            "Epoch 31/45\n",
            "245/245 [==============================] - ETA: 0s - loss: 0.5944 - accuracy: 0.9745\n",
            "Epoch 00031: val_loss improved from 0.51925 to 0.51867, saving model to output/weights-031-0.5187.hdf5\n",
            "245/245 [==============================] - 53s 218ms/step - loss: 0.5944 - accuracy: 0.9745 - val_loss: 0.5187 - val_accuracy: 0.9865\n",
            "Epoch 32/45\n",
            "245/245 [==============================] - ETA: 0s - loss: 0.5399 - accuracy: 0.9764\n",
            "Epoch 00032: val_loss improved from 0.51867 to 0.49345, saving model to output/weights-032-0.4935.hdf5\n",
            "245/245 [==============================] - 54s 221ms/step - loss: 0.5399 - accuracy: 0.9764 - val_loss: 0.4935 - val_accuracy: 0.9862\n",
            "Epoch 33/45\n",
            "245/245 [==============================] - ETA: 0s - loss: 0.5065 - accuracy: 0.9772\n",
            "Epoch 00033: val_loss improved from 0.49345 to 0.43881, saving model to output/weights-033-0.4388.hdf5\n",
            "245/245 [==============================] - 53s 218ms/step - loss: 0.5065 - accuracy: 0.9772 - val_loss: 0.4388 - val_accuracy: 0.9925\n",
            "Epoch 34/45\n",
            "245/245 [==============================] - ETA: 0s - loss: 0.4654 - accuracy: 0.9804\n",
            "Epoch 00034: val_loss improved from 0.43881 to 0.42590, saving model to output/weights-034-0.4259.hdf5\n",
            "245/245 [==============================] - 54s 220ms/step - loss: 0.4654 - accuracy: 0.9804 - val_loss: 0.4259 - val_accuracy: 0.9852\n",
            "Epoch 35/45\n",
            "245/245 [==============================] - ETA: 0s - loss: 0.4672 - accuracy: 0.9749\n",
            "Epoch 00035: val_loss did not improve from 0.42590\n",
            "245/245 [==============================] - 53s 215ms/step - loss: 0.4672 - accuracy: 0.9749 - val_loss: 0.6548 - val_accuracy: 0.9281\n",
            "Epoch 36/45\n",
            "245/245 [==============================] - ETA: 0s - loss: 0.5006 - accuracy: 0.9738\n",
            "Epoch 00036: val_loss did not improve from 0.42590\n",
            "245/245 [==============================] - 52s 210ms/step - loss: 0.5006 - accuracy: 0.9738 - val_loss: 0.5982 - val_accuracy: 0.9520\n",
            "Epoch 37/45\n",
            "245/245 [==============================] - ETA: 0s - loss: 0.5194 - accuracy: 0.9761\n",
            "Epoch 00037: val_loss did not improve from 0.42590\n",
            "245/245 [==============================] - 52s 211ms/step - loss: 0.5194 - accuracy: 0.9761 - val_loss: 0.4973 - val_accuracy: 0.9811\n",
            "Epoch 38/45\n",
            "245/245 [==============================] - ETA: 0s - loss: 0.5108 - accuracy: 0.9768\n",
            "Epoch 00038: val_loss did not improve from 0.42590\n",
            "245/245 [==============================] - 51s 210ms/step - loss: 0.5108 - accuracy: 0.9768 - val_loss: 0.5009 - val_accuracy: 0.9833\n",
            "Epoch 39/45\n",
            "245/245 [==============================] - ETA: 0s - loss: 0.5068 - accuracy: 0.9788\n",
            "Epoch 00039: val_loss did not improve from 0.42590\n",
            "245/245 [==============================] - 52s 214ms/step - loss: 0.5068 - accuracy: 0.9788 - val_loss: 0.4466 - val_accuracy: 0.9915\n",
            "Epoch 40/45\n",
            "245/245 [==============================] - ETA: 0s - loss: 0.4528 - accuracy: 0.9825\n",
            "Epoch 00040: val_loss improved from 0.42590 to 0.41849, saving model to output/weights-040-0.4185.hdf5\n",
            "245/245 [==============================] - 54s 220ms/step - loss: 0.4528 - accuracy: 0.9825 - val_loss: 0.4185 - val_accuracy: 0.9876\n",
            "Epoch 41/45\n",
            "245/245 [==============================] - ETA: 0s - loss: 0.4558 - accuracy: 0.9780\n",
            "Epoch 00041: val_loss did not improve from 0.41849\n",
            "245/245 [==============================] - 53s 216ms/step - loss: 0.4558 - accuracy: 0.9780 - val_loss: 0.4508 - val_accuracy: 0.9848\n",
            "Epoch 42/45\n",
            "245/245 [==============================] - ETA: 0s - loss: 0.4785 - accuracy: 0.9784\n",
            "Epoch 00042: val_loss did not improve from 0.41849\n",
            "245/245 [==============================] - 52s 212ms/step - loss: 0.4785 - accuracy: 0.9784 - val_loss: 0.4931 - val_accuracy: 0.9912\n",
            "Epoch 43/45\n",
            "245/245 [==============================] - ETA: 0s - loss: 0.5479 - accuracy: 0.9780\n",
            "Epoch 00043: val_loss did not improve from 0.41849\n",
            "245/245 [==============================] - 52s 213ms/step - loss: 0.5479 - accuracy: 0.9780 - val_loss: 0.4698 - val_accuracy: 0.9908\n",
            "Epoch 44/45\n",
            "245/245 [==============================] - ETA: 0s - loss: 0.5040 - accuracy: 0.9816\n",
            "Epoch 00044: val_loss did not improve from 0.41849\n",
            "245/245 [==============================] - 52s 211ms/step - loss: 0.5040 - accuracy: 0.9816 - val_loss: 0.4621 - val_accuracy: 0.9936\n",
            "Epoch 45/45\n",
            "245/245 [==============================] - ETA: 0s - loss: 0.4664 - accuracy: 0.9842\n",
            "Epoch 00045: val_loss improved from 0.41849 to 0.40134, saving model to output/weights-045-0.4013.hdf5\n",
            "245/245 [==============================] - 54s 219ms/step - loss: 0.4664 - accuracy: 0.9842 - val_loss: 0.4013 - val_accuracy: 0.9953\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VV_q9wehYhjo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "62001292-365c-45ba-80e7-c059a96c3b39"
      },
      "source": [
        "model.save('../../alexnet.model', overwrite=True)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/resource_variable_ops.py:1817: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n",
            "INFO:tensorflow:Assets written to: ../../alexnet.model/assets\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZUDwDBdKhdsd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.load_weights('output/weights-045-0.4013.hdf5')"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S38t_OV-BD8G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "print(\"[INFO] loading model...\")\n",
        "model = load_model('../../alexnet_45.model')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d_AX--FgBPuy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "7de93ddc-3290-478d-9e9b-c44d799c95d9"
      },
      "source": [
        "from os.path import basename, splitext\n",
        "\n",
        "imagePaths = list((paths.list_images('../../Test')))\n",
        "new_list = [splitext(basename(x))[0] for x in imagePaths]\n",
        "fin_list = list(zip(imagePaths, new_list))\n",
        "fin_list = [x[0] for x in sorted(fin_list,key=lambda x: int(x[1]))]\n",
        "print(fin_list[0])\n",
        "length = len(imagePaths)\n",
        "sdl = SimpleDatasetLoader(preprocessors=[])\n",
        "data = sdl.load_test(fin_list, verbose=2000, length=length)\n",
        "data = data.astype(\"float\") / 255.0"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "../../Test/00000.png\n",
            "[INFO] processed 2000/12630\n",
            "[INFO] processed 4000/12630\n",
            "[INFO] processed 6000/12630\n",
            "[INFO] processed 8000/12630\n",
            "[INFO] processed 10000/12630\n",
            "[INFO] processed 12000/12630\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xAWYeArxG-VL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.preprocessing import LabelBinarizer\n",
        "import h5py\n",
        "\n",
        "db = h5py.File('../../test.hdf5', 'r')\n",
        "testImages = np.array(db[\"images\"])\n",
        "testImages = testImages.astype('float') / 255.0"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SFGM4CQhqVnG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "labelNames = open(\"../../signnames.csv\").read().strip().split(\"\\n\")[1:]\n",
        "labelNames = [l.split(\",\")[1] for l in labelNames]"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R7P2yLcO-CXi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predictions = model.predict(data ,batch_size=128)\n",
        "pred = predictions.argmax(axis=1)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tZs2wp3wHqyC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "17c8d4e2-6810-4961-e25f-bca190b4bc40"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "test_df = pd.read_csv('Test.csv')\n",
        "labels = test_df['ClassId'].values\n",
        "print(labels[1000], pred[1000])"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "17 17\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7LacnXxuII3t",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 867
        },
        "outputId": "4eb7e59e-a27e-4cbe-d278-3d6fbc4ce156"
      },
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "print(classification_report(labels,\n",
        "  predictions.argmax(axis=1), target_names=labelNames))"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                                                    precision    recall  f1-score   support\n",
            "\n",
            "                              Speed limit (20km/h)       0.85      0.95      0.90        60\n",
            "                              Speed limit (30km/h)       0.98      0.99      0.99       720\n",
            "                              Speed limit (50km/h)       0.99      0.98      0.99       750\n",
            "                              Speed limit (60km/h)       0.99      0.96      0.97       450\n",
            "                              Speed limit (70km/h)       0.99      0.98      0.98       660\n",
            "                              Speed limit (80km/h)       0.94      0.99      0.96       630\n",
            "                       End of speed limit (80km/h)       0.98      0.87      0.92       150\n",
            "                             Speed limit (100km/h)       0.98      0.98      0.98       450\n",
            "                             Speed limit (120km/h)       0.97      0.96      0.96       450\n",
            "                                        No passing       0.98      1.00      0.99       480\n",
            "      No passing for vehicles over 3.5 metric tons       1.00      0.99      0.99       660\n",
            "             Right-of-way at the next intersection       0.93      0.98      0.96       420\n",
            "                                     Priority road       1.00      0.99      0.99       690\n",
            "                                             Yield       1.00      1.00      1.00       720\n",
            "                                              Stop       1.00      1.00      1.00       270\n",
            "                                       No vehicles       1.00      0.97      0.99       210\n",
            "          Vehicles over 3.5 metric tons prohibited       0.97      1.00      0.98       150\n",
            "                                          No entry       1.00      0.97      0.98       360\n",
            "                                   General caution       0.98      0.98      0.98       390\n",
            "                       Dangerous curve to the left       0.82      1.00      0.90        60\n",
            "                      Dangerous curve to the right       0.83      0.96      0.89        90\n",
            "                                      Double curve       0.99      0.97      0.98        90\n",
            "                                        Bumpy road       0.99      0.87      0.92       120\n",
            "                                     Slippery road       0.97      0.91      0.94       150\n",
            "                         Road narrows on the right       0.81      0.99      0.89        90\n",
            "                                         Road work       0.90      0.99      0.94       480\n",
            "                                   Traffic signals       0.99      0.97      0.98       180\n",
            "                                       Pedestrians       0.95      0.98      0.97        60\n",
            "                                 Children crossing       1.00      0.75      0.85       150\n",
            "                                 Bicycles crossing       0.83      1.00      0.90        90\n",
            "                                Beware of ice/snow       0.97      0.71      0.82       150\n",
            "                             Wild animals crossing       0.99      0.97      0.98       270\n",
            "               End of all speed and passing limits       0.94      1.00      0.97        60\n",
            "                                  Turn right ahead       0.97      1.00      0.98       210\n",
            "                                   Turn left ahead       0.99      1.00      1.00       120\n",
            "                                        Ahead only       0.99      0.99      0.99       390\n",
            "                              Go straight or right       1.00      1.00      1.00       120\n",
            "                               Go straight or left       1.00      0.98      0.99        60\n",
            "                                        Keep right       0.98      1.00      0.99       690\n",
            "                                         Keep left       1.00      0.98      0.99        90\n",
            "                              Roundabout mandatory       0.99      0.94      0.97        90\n",
            "                                 End of no passing       1.00      0.95      0.97        60\n",
            "End of no passing by vehicles over 3.5 metric tons       0.95      0.87      0.91        90\n",
            "\n",
            "                                          accuracy                           0.97     12630\n",
            "                                         macro avg       0.96      0.96      0.96     12630\n",
            "                                      weighted avg       0.97      0.97      0.97     12630\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hoUcdI-dNTr2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "40d23424-2809-49fc-e19f-18f043ed36b4"
      },
      "source": [
        " from sklearn.metrics import accuracy_score\n",
        "\n",
        " print(accuracy_score(labels, pred))"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.973396674584323\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AWglyUcA-NAy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import cv2\n",
        "\n",
        "image = cv2.imread('../../40_1.jpg')\n",
        "for p in [aap, iap]:\n",
        "  image = p.preprocess(image)\n",
        "\n",
        "test_data = np.array([image])\n",
        "test_data = test_data.astype('float') / 255.0\n",
        "predict = model.predict(test_data)\n",
        "print(predict.argmax(axis=1))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}