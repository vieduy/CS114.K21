{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "face_mask_correctly.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vieduy/CS114.K21/blob/master/face_mask_correctly.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n3rV7G_GaKOU"
      },
      "source": [
        "# Import packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zKb3c3-O_hYX",
        "outputId": "2000f441-0d8a-4bd0-fbf6-897af5488223",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!gdown --id 1bea1kfxQuGAf0nZycQcfFZDcHtCZf7ta"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1bea1kfxQuGAf0nZycQcfFZDcHtCZf7ta\n",
            "To: /content/test.zip\n",
            "\r0.00B [00:00, ?B/s]\r3.20MB [00:00, 50.7MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CDZ7jR23_ntz",
        "outputId": "472b54db-e0d4-4edc-bc88-14170f51d681",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!gdown --id 1ucbjmTe0hdOt_Ke0VTx9kLJL6n7bjfCk"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1ucbjmTe0hdOt_Ke0VTx9kLJL6n7bjfCk\n",
            "To: /content/train.zip\n",
            "\r0.00B [00:00, ?B/s]\r9.44MB [00:00, 93.5MB/s]\r15.6MB [00:00, 95.4MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rlypGE-0-Nzg"
      },
      "source": [
        "!unzip test.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S_0PoEnV_4hL"
      },
      "source": [
        "!unzip train.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6AMPUHvi2kpN"
      },
      "source": [
        "import torch\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "import matplotlib.pyplot as plt\n",
        "import torchvision\n",
        "import numpy as np\n",
        "import random\n",
        "import torchvision.transforms as transforms\n",
        "import imageio\n",
        "\n",
        "import glob\n",
        "from PIL import Image\n",
        "import cv2\n",
        "import torch.nn as nn\n",
        "from sklearn import svm\n",
        "from torch.hub import load_state_dict_from_url\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import plot_confusion_matrix\n",
        "from sklearn.metrics import accuracy_score"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O-mXg0gWadTL"
      },
      "source": [
        "## Visualize dataset\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uc3VKsrzaU4u"
      },
      "source": [
        "# Create dataloader"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8H3d7QiR37U4"
      },
      "source": [
        "class FM_Dataset(TensorDataset):\n",
        "    def __init__(self, root):\n",
        "        super(FM_Dataset, self).__init__()\n",
        "        self.root = root\n",
        "        self.labels = []\n",
        "        self.img_paths = []\n",
        "        self.transform =  transforms.Compose([\n",
        "          transforms.ToPILImage(),\n",
        "          transforms.ToTensor()])\n",
        "\n",
        "        folder_path = glob.glob(root+'/*')\n",
        "        for label_path in folder_path:\n",
        "          self.img_paths.extend(glob.glob(label_path+'/*'))\n",
        "        \n",
        "        # print(self.img_paths[0])\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        img_path = self.img_paths[idx]\n",
        "        img = cv2.imread(img_path)\n",
        "        img = np.resize(img, (227, 227, 3))\n",
        "        img = self.transform(img)\n",
        "\n",
        "        label = img_path.split('/')[-2]\n",
        "        if label == 'incorrect':\n",
        "          label = 0\n",
        "        else:\n",
        "          label = 1\n",
        "\n",
        "        return img, label\n",
        "\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.img_paths) "
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VKntJl8uaYhd"
      },
      "source": [
        "# Initialize dataloader"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1gv6kscM_D1Q"
      },
      "source": [
        "train_dataset = FM_Dataset('face_mask_dataset')\n",
        "trainset_loader = DataLoader(train_dataset,\n",
        "                                 shuffle=False,\n",
        "                                 batch_size=4,\n",
        "                                 pin_memory=True,\n",
        "                                #  drop_last=True\n",
        "                                 )\n",
        "\n",
        "# print(list(trainset_loader)[0][0][0])\n",
        "#Now using the AlexNet\n",
        "# AlexNet_model = torch.hub.load('pytorch/vision:v0.6.0', 'alexnet', pretrained=True)"
      ],
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GkZ6v55Paj1E"
      },
      "source": [
        "# Download AlexNet pretrained"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JG5SJkZx5_sq",
        "outputId": "01aad1ed-b14d-46ac-8868-943b326e030e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import torchvision.models as models\n",
        "\n",
        "AlexNet_model = models.alexnet(pretrained=True)\n",
        "\n",
        "for param in AlexNet_model.parameters():\n",
        "    param.requires_grad = False\n",
        "AlexNet_model.cuda()"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AlexNet(\n",
              "  (features): Sequential(\n",
              "    (0): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n",
              "    (1): ReLU(inplace=True)\n",
              "    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
              "    (4): ReLU(inplace=True)\n",
              "    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (7): ReLU(inplace=True)\n",
              "    (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (9): ReLU(inplace=True)\n",
              "    (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (11): ReLU(inplace=True)\n",
              "    (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (avgpool): AdaptiveAvgPool2d(output_size=(6, 6))\n",
              "  (classifier): Sequential(\n",
              "    (0): Dropout(p=0.5, inplace=False)\n",
              "    (1): Linear(in_features=9216, out_features=4096, bias=True)\n",
              "    (2): ReLU(inplace=True)\n",
              "    (3): Dropout(p=0.5, inplace=False)\n",
              "    (4): Linear(in_features=4096, out_features=4096, bias=True)\n",
              "    (5): ReLU(inplace=True)\n",
              "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2fgLbyNAP-Va"
      },
      "source": [
        "# __all__ = ['AlexNet', 'alexnet']\n",
        "\n",
        "\n",
        "# model_urls = {\n",
        "#     'alexnet': 'https://download.pytorch.org/models/alexnet-owt-4df8aa71.pth',\n",
        "# }\n",
        "\n",
        "\n",
        "# class AlexNet(nn.Module):\n",
        "\n",
        "#     def __init__(self, num_classes=1000):\n",
        "#         super(AlexNet, self).__init__()\n",
        "#         self.features = nn.Sequential(\n",
        "#             nn.Conv2d(3, 64, kernel_size=11, stride=4, padding=2),\n",
        "#             nn.ReLU(inplace=True),\n",
        "#             nn.MaxPool2d(kernel_size=3, stride=2),\n",
        "#             nn.Conv2d(64, 192, kernel_size=5, padding=2),\n",
        "#             nn.ReLU(inplace=True),\n",
        "#             nn.MaxPool2d(kernel_size=3, stride=2),\n",
        "#             nn.Conv2d(192, 384, kernel_size=3, padding=1),\n",
        "#             nn.ReLU(inplace=True),\n",
        "#             nn.Conv2d(384, 256, kernel_size=3, padding=1),\n",
        "#             nn.ReLU(inplace=True),\n",
        "#             nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
        "#             nn.ReLU(inplace=True),\n",
        "#             nn.MaxPool2d(kernel_size=3, stride=2),\n",
        "#         )\n",
        "#         self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n",
        "#         self.classifier = nn.Sequential(\n",
        "#             nn.Dropout(),\n",
        "#             nn.Linear(256 * 6 * 6, 4096),\n",
        "#             nn.ReLU(inplace=True),\n",
        "#             nn.Dropout(),\n",
        "#             nn.Linear(4096, 4096),\n",
        "#             nn.ReLU(inplace=True),\n",
        "#             nn.Linear(4096, num_classes),\n",
        "#         )\n",
        "\n",
        "#     def forward(self, x):\n",
        "#         x = self.features(x)\n",
        "#         x = self.avgpool(x)\n",
        "#         x = x.view(x.size(0), 256 * 6 * 6)\n",
        "#         x = self.classifier(x)\n",
        "#         return x\n",
        "\n",
        "\n",
        "# def alexnet(pretrained=False, progress=True, **kwargs):\n",
        "#     r\"\"\"AlexNet model architecture from the\n",
        "#     `\"One weird trick...\" <https://arxiv.org/abs/1404.5997>`_ paper.\n",
        "#     Args:\n",
        "#         pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
        "#         progress (bool): If True, displays a progress bar of the download to stderr\n",
        "#     \"\"\"\n",
        "#     model = AlexNet(**kwargs)\n",
        "#     if pretrained:\n",
        "#         state_dict = load_state_dict_from_url(model_urls['alexnet'],\n",
        "#                                               progress=progress)\n",
        "#         model.load_state_dict(state_dict)\n",
        "#     return model\n",
        "\n",
        "\n",
        "# # AlexNet_model_1 = AlexNet()\n",
        "# # AlexNet_model_2 = AlexNet()\n",
        "# AlexNet_model = AlexNet()\n",
        "# state_dict = load_state_dict_from_url(model_urls['alexnet'],)\n",
        "# # AlexNet_model_1.load_state_dict(state_dict)\n",
        "# # AlexNet_model_2.load_state_dict(state_dict)\n",
        "\n",
        "# # AlexNet_model_1.cuda()\n",
        "# # AlexNet_model_2.cuda()\n",
        "\n",
        "# #Model description\n",
        "# # AlexNet_model.eval()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3XGupJe3bTJm"
      },
      "source": [
        "# Create 2 models \n",
        "- Model 1: Remove last FC\n",
        "- Model 2: Remove 2 last FC"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "81DpAyZzmBUk"
      },
      "source": [
        "new_classifier = nn.Sequential(*list(AlexNet_model.classifier.children())[:-2])\n",
        "AlexNet_model.classifier = new_classifier"
      ],
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MlA84EFvRCmG"
      },
      "source": [
        "# new_classifier_1 = nn.Sequential(*list(AlexNet_model_1.classifier.children())[:-1])\n",
        "# new_classifier_2 = nn.Sequential(*list(AlexNet_model_2.classifier.children())[:-2])\n",
        "# AlexNet_model_1.classifier = new_classifier_1\n",
        "# AlexNet_model_2.classifier = new_classifier_2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sW-sUxJ3bt0L"
      },
      "source": [
        "# Features extraction from 2 these models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XD1IH03ZmF0j",
        "outputId": "725bf954-ad63-40d3-8171-6da10035c5b4"
      },
      "source": [
        "features = []\n",
        "labels = []\n",
        "\n",
        "# loop over the dataset multiple times\n",
        "for i, data in enumerate(trainset_loader):\n",
        "  img, label = data[0].cuda(), data[1].cuda()\n",
        "  with torch.no_grad():\n",
        "    output = AlexNet_model(img)\n",
        "    output = output.cpu()\n",
        "\n",
        "    # if i == 0:\n",
        "    #   print(img[0][0])\n",
        "    #   print(output[0][0])\n",
        "    features.extend(np.squeeze(output.data.numpy()))\n",
        "\n",
        "    labels.extend(label.cpu().numpy())\n",
        "\n",
        "print('Finished extracting features of AlexNet')"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Finished extracting features of AlexNet\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-BK6zokvHkPm",
        "outputId": "c4a67422-8652-4139-adfc-75b85b6ed312"
      },
      "source": [
        "print(features[0])"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[  0.58794993  -3.7071877   -0.35133108 ...  -4.0289917  -14.862189\n",
            "   0.01714147]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ORgOoLaRC3jE",
        "outputId": "e8c5205b-cc80-4ac6-d3e2-36234cb2ea38"
      },
      "source": [
        "# features_1 = []\n",
        "# features_2 = []\n",
        "# labels = []\n",
        "\n",
        "# for epoch in range(1):  # loop over the dataset multiple times\n",
        "#     for _, data in enumerate(trainset_loader):\n",
        "#         img, label = data[0].cuda(), data[1].cuda()\n",
        "\n",
        "#         output_1 = AlexNet_model_1(img)\n",
        "#         output_1 = output_1.cpu()\n",
        "#         features_1.extend(np.squeeze(output_1.data.numpy()))\n",
        "\n",
        "#         output_2 = AlexNet_model_2(img)\n",
        "#         output_2 = output_2.cpu()\n",
        "#         features_2.extend(np.squeeze(output_2.data.numpy()))\n",
        "        \n",
        "#         labels.extend(label.cpu().numpy())\n",
        "\n",
        "# print('Finished extracting features of AlexNet')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Finished extracting features of AlexNet\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sfyMVCuMQJz4"
      },
      "source": [
        "# #Updating the second classifier\n",
        "# AlexNet_model.classifier[4] = nn.Linear(4096,4096)\n",
        "\n",
        "# #Updating the third and the last classifier that is the output layer of the network. Make sure to have 10 output nodes if we are going to get 10 class labels through our model.\n",
        "# AlexNet_model.classifier[6] = nn.Linear(1024,10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PqtJ8CeNTang",
        "outputId": "758e51fa-6e43-4c46-d4c5-1a08c6f3f888"
      },
      "source": [
        "print(np.shape(features))\n",
        "print(np.shape(labels))"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(160, 4096)\n",
            "(160,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QvtTkIWxb5LM"
      },
      "source": [
        "## Create SVM model and train with 2 feature-map (80% training - 20% testing)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zaFqElTVmSJh",
        "outputId": "f4c37fb6-dcf2-4e6c-de55-f79a376dce24"
      },
      "source": [
        "clf = make_pipeline(StandardScaler(), SVC(gamma='auto'))\n",
        "clf.fit(features, labels)"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(memory=None,\n",
              "         steps=[('standardscaler',\n",
              "                 StandardScaler(copy=True, with_mean=True, with_std=True)),\n",
              "                ('svc',\n",
              "                 SVC(C=1.0, break_ties=False, cache_size=200, class_weight=None,\n",
              "                     coef0=0.0, decision_function_shape='ovr', degree=3,\n",
              "                     gamma='auto', kernel='rbf', max_iter=-1, probability=False,\n",
              "                     random_state=None, shrinking=True, tol=0.001,\n",
              "                     verbose=False))],\n",
              "         verbose=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dgd9qL16VTQ0"
      },
      "source": [
        "# clf_1 = make_pipeline(StandardScaler(), SVC(gamma='auto'))\n",
        "# clf_1.fit(features_1, labels)\n",
        "\n",
        "# clf_2 = make_pipeline(StandardScaler(), SVC(gamma='auto'))\n",
        "# clf_2.fit(features_2, labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VVRNFrQFcKg9"
      },
      "source": [
        "# Compare accuracy between 2 models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SnxWadA0EzSq"
      },
      "source": [
        "test_dataset = FM_Dataset('test')"
      ],
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qgZhEuUmuyJG"
      },
      "source": [
        "testset_loader = DataLoader(test_dataset,\n",
        "                                 shuffle=False,\n",
        "                                 batch_size=1,\n",
        "                                 pin_memory=True\n",
        "                                #  drop_last=True\n",
        "                                 )"
      ],
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fmZ5qy-YvE7F",
        "outputId": "8084d30f-7e86-414b-ac88-c8be50d95322"
      },
      "source": [
        "features_test = []\n",
        "labels_test = []\n",
        " # loop over the dataset multiple times\n",
        "for _, il in enumerate(testset_loader):\n",
        "    image, label = il[0].cuda(), il[1].cuda()\n",
        "\n",
        "    output = AlexNet_model(image)\n",
        "    output = output.cpu()\n",
        "    features_test.append(np.squeeze(output.data.numpy()))\n",
        "    labels_test.append(label.cpu().numpy())\n",
        "\n",
        "print('Finished extracting features of AlexNet')"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Finished extracting features of AlexNet\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tyDDigLrvv60",
        "outputId": "bba6d83e-f4fb-4237-ecc8-5a6a47ce283c"
      },
      "source": [
        "print((features_test[0]))"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[  0.61208904  -7.6072054    1.2467775  ...  -4.274523   -13.041966\n",
            "  -1.9171482 ]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X7xj0AH5mWNr",
        "outputId": "045f4b19-8b67-4637-a4c2-dedfc2ecda2e"
      },
      "source": [
        "y_pre = clf.predict(features_test)\n",
        "\n",
        "print(accuracy_score(y_pre, labels_test))"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.7\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l4uSpATNcb6R"
      },
      "source": [
        "# Confusion matrix of model over 40 samples (20% testing) "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "1SUp_v_pXy42",
        "outputId": "b0038f51-4d6a-47e5-a43e-e95543d7bbd5"
      },
      "source": [
        "plot_confusion_matrix(clf, features_test, labels_test)\n",
        "plt.show() "
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FFISKV_eeRnw",
        "outputId": "2379e547-7623-41b0-a0ff-93d248dac59a"
      },
      "source": [
        "# y_pre_1 = clf_1.predict(features_test)\n",
        "# y_pre_2 = clf_2.predict(features_test)\n",
        "\n",
        "# print(accuracy_score(y_pre_1, labels_test))\n",
        "# print(accuracy_score(y_pre_2, labels_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.5\n",
            "0.65\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LW0C1UAyWPuS",
        "outputId": "743b9df0-7888-42bb-b54a-359cf7b8519e"
      },
      "source": [
        "from PIL import Image\n",
        "from torch.autograd import Variable\n",
        "\n",
        "# img_path = '../../pra2.jpg'\n",
        "img_path = '../../201-with-mask.jpg'\n",
        "\n",
        "img_pre = cv2.imread(img_path)\n",
        "img = np.resize(img_pre, (227, 227, 3))\n",
        "\n",
        "preprocess = transforms.Compose([\n",
        "       transforms.ToPILImage(),\n",
        "       transforms.ToTensor()\n",
        "    ])\n",
        "img_tensor = preprocess(img)\n",
        "img_tensor.unsqueeze_(0)\n",
        "img_var = Variable(img_tensor)\n",
        "img_var = img_var.cuda()\n",
        "out = AlexNet_model(img_var)\n",
        "\n",
        "newOut = np.squeeze(out)\n",
        "newOut = newOut.cpu()\n",
        "\n",
        "newOut = torch.unsqueeze(newOut, 0)\n",
        "pred = clf.predict(newOut.data.numpy())\n",
        "print(pred)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}